## 人工神經網路 (Artificial Neural Network) (作者：Bridan)

[NEURO](http://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)  這門學問是我工作時才學習得的知識，多年前曾有一篇 [洗衣機](http://4rdp.blogspot.tw/2009/07/washing-machine.html) 貼文提到它，當時第一次知道這東西時，已經從研究所畢業好幾年，書局也沒幾本書可以參考，書中一堆數學式，有看沒有很懂，九O年代網路剛興起，沒甚麼資料可查，正好一位大學同學在大同工學院攻讀博士班主攻語音辨識，NEURO 就是用於學習辨識語音模式的解決方案之一，因此跟主管提出學習計畫，對授課教授表達旁聽的想法，就每周固定時間去大同工學院上課，我不需要學分，所以不用繳學費、不必考試、不必交作業，自備課本上了一個學期的課，這種學習方法在我準備插班大學考試也用過，並認識一些朋友。最近上網查，沒什麼人對 NEURO 議題，提供簡單的實例，以供初學者參考入門，現在將個人所知的做個紀錄分享。

類神經網路有很多解決方案，這裡使用 BP 方法。首先認識神經元的數學模型，

![](../img/BridanAN.gif)

MP (MultiLayer Perceptron) 模型公式：

### 一、先計算內部數值

Ui = Σ Wji Xj – θi

Wji  = 連結強度

Xj   = 神經元 j 所傳來之訊號

θi  = 神經元 i 之閥值

### 二、計算輸出數值

Yi = f(Ui) = Yi 處理單元函數

f    = 轉換函數，通常為階梯函數(Step function)

例如 Yi = 1 / (1 + exp(-Ui))

### 三、δ差距量 ，用來修正權重

{T}目標輸出量

{Y}推論輸出量

差距量 = 目標輸出量 – 推論輸出量 = δi = Ti – Yi

本文範例採取的修正算式 δi = Yi‧(1 - Yi)‧(Ti – Yi)

### 四、計算輸出閥值及權重變量

η：學習速率，控制權重修正幅度 

輸出單元閥值改變量 = △θi = - η‧δi

權重改變量 = △Wji = Xj‧η‧δi

### 五、修正下一輪閥值及權重

θi = θi + △θi 

Wji = Wji + △Wji

### 六、檢驗成果

總錯誤率 = 誤分類案例總數/範例總數


**依問題的複雜層度，利用它組合一知識神經網路，基本上有三大層－輸入層、隱藏層及輸出層。**

![](../img/BridanNeuro_XOR.jpg)

最後整理一個 [試算表](https://docs.google.com/spreadsheet/ccc?key=0AvTFWEwZaQ8_dEI1YlBla081dDJ0MERiY3NSNzcwMFE&usp=sharing) 提供有興趣的朋友參考，以 XOR 邏輯為例，X1, X2 為輸入，Y為輸出，用 #3, #4, #5 三個神經元學習，H3, H4 是隱藏層(夾在輸入及輸出之間)，簡單的問題一個隱藏層就夠，複雜的可能需要兩層。使用四種組合狀態重複訓練，最後它會穩定判別輸入，並給予適合的答案。

以 [遞迴或遞歸 (Recursion)](http://4rdp.blogspot.tw/2009/08/recursion.html)  *這樣技術，可將非線性數學問題收斂求解，* **能處理類似邏輯型式的問題** ，供大家參考。

(本文來自「研發養成所」 Bridan 的網誌，原文網址為 <http://4rdp.blogspot.tw/2013/10/artificial-neural-network.html> ，由陳鍾誠編輯後納入程式人雜誌)

